# -*- coding: utf-8 -*-
"""Losistic_regression.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14YtL4hN2ZE1-yXLV9VZrXmhdwo_Os1te
"""

from torch import tensor
from torch import nn
from torch import sigmoid
from torch import tanh
from torch import relu
import torch.nn.functional as F
import torch.optim as optim

x_data = tensor([[1.0], [2.0], [3.0], [4.0],[5.0]])
y_data = tensor([[0.0], [0.0], [0.0], [1.0],[1.0]])

class Model(nn.Module):
    def __init__(self):
        
        super(Model, self).__init__()
        self.linear = nn.Linear(1, 1) 

    def forward(self, x):
        
        #y_pred = F.tanh(self.linear(x)) not relevant for logistic regression as output is (-1,1)
        #y_pred = F.relu(self.linear(x)) gives loss 40 everytime 
        y_pred = F.sigmoid(self.linear(x))
        return y_pred

model = Model()

criterion = nn.BCELoss(reduction='mean')
optimizer = optim.SGD(model.parameters(), lr=0.01)

for epoch in range(1000):
   
    y_pred = model(x_data)
   
    loss = criterion(y_pred, y_data)
    print("Epoch:",epoch," "," Loss:",loss.item())

    optimizer.zero_grad()
    loss.backward()
    optimizer.step()


input = model(tensor([[3.0]]))
print("\nPrediction for 3:",input.item()) 
input = model(tensor([[2.0]]))
print("Prediction for 2:",input.item())
input = model(tensor([[6.0]])) 
print("Prediction for 6:",input.item()) 
input = model(tensor([[7.0]])) 
print("Prediction for 7:",input.item())